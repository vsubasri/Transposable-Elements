{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff664cb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/katherineqin/Transposable-Elements/Analysis/Data/kics_structural_variations.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#warnings.filterwarnings(action='once') #shows warnings once\u001b[39;00m\n\u001b[1;32m     16\u001b[0m dataFilePath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m kicsSVdf \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataFilePath\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkics_structural_variations.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m lfsSVdf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dataFilePath,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlfs_structural_variations.txt\u001b[39m\u001b[38;5;124m'\u001b[39m), sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, header \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     20\u001b[0m kicsClinicdf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dataFilePath,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkics_clinical_main.tsv\u001b[39m\u001b[38;5;124m'\u001b[39m), sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, header \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/katherineqin/Transposable-Elements/Analysis/Data/kics_structural_variations.txt'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "load original df\n",
    "\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #supresses warnings for now\n",
    "#warnings.filterwarnings(action='once') #shows warnings once\n",
    "\n",
    "dataFilePath = os.path.join(os.getcwd(),'Data')\n",
    "\n",
    "kicsSVdf = pd.read_csv(os.path.join(dataFilePath,'kics_structural_variations.txt'), sep = '\\t', header = 0)\n",
    "lfsSVdf = pd.read_csv(os.path.join(dataFilePath,'lfs_structural_variations.txt'), sep = '\\t', header = 0)\n",
    "kicsClinicdf = pd.read_csv(os.path.join(dataFilePath,'kics_clinical_main.tsv'), sep = '\\t', header = 0)\n",
    "lfsClinicdf = pd.read_csv(os.path.join(dataFilePath,'lfs_clinical_main.tsv'), sep = '\\t', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82781e2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "filter dfs\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "kicsSVF = kicsSVdf.loc[kicsSVdf['AnnotSV type'] == 'full']\n",
    "lfsSVF = lfsSVdf.loc[lfsSVdf['AnnotSV type'] == 'full']\n",
    "\n",
    "kicsSVF['SV chrom'] = kicsSVF['SV chrom'].astype(str)\n",
    "lfsSVF['SV chrom'] = lfsSVF['SV chrom'].astype(str)\n",
    "\n",
    "kicsSVnum = kicsSVF['sample_id'].count()\n",
    "lfsSVnum = lfsSVF['sample_id'].count()\n",
    "\n",
    "#print(kicsSVnum, lfsSVnum)\n",
    "\n",
    "#to improve this, multi-index would be good, that way we can have less columns\n",
    "mergedSVdf = pd.DataFrame(data = {'kics':kicsSVF['SV type'], 'kChrom':kicsSVF['SV chrom'], \n",
    "                                  'kId':kicsSVF['sample_id'], 'lId':lfsSVF['sample_id'],\n",
    "                                  'lfs':lfsSVF['SV type'], 'lChrom':lfsSVF['SV chrom']})\n",
    "\n",
    "#print(mergedSVdf.head(30))\n",
    "\n",
    "#print(kicsClinicdf.columns)#['WGS-Id'].value_counts())#head(50))\n",
    "#print(mergedSVdf['kId'].value_counts())#head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a584f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "1. Graph for frequency of SV types\n",
    "2. Graphs for frequency of SV types specific to chromosomes\n",
    "\n",
    "Function to graph bar graphs\n",
    "\n",
    "\"\"\"\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def BarGraphNormalized(label1: str, label2:str, df: pd.DataFrame, col1: str, col2: str,\n",
    "                        xTitle: str, yTitle: str, divisor1: float, divisor2: float,\n",
    "                        labels: list):\n",
    "    #'kics', 'lfs', invdf, 'kchrom', 'lchrom', 'Chromosomes','Frequency','Graph2-INV',kicsSVnum, lfsSVnum\n",
    "\n",
    "    title = label1 + \" \" + label2\n",
    "    count1 = df[col1].value_counts()\n",
    "    count2 = df[col2].value_counts()\n",
    "    \n",
    "    x_axis = np.arange(len(labels))\n",
    "        \n",
    "    for i in labels:\n",
    "        if (not(i in count1)):\n",
    "            add = pd.Series([0], index=[i])\n",
    "            count1 = count1.append(add)\n",
    "        if (not(i in count2)):\n",
    "            add = pd.Series([0], index=[i])\n",
    "            count2 = count2.append(add)\n",
    "    \n",
    "    plt.bar(x_axis - 0.2, [count1[a] for a in labels]/divisor1, 0.4, label = label1)\n",
    "    plt.bar(x_axis + 0.2, [count2[a] for a in labels]/divisor2, 0.4, label = label2)\n",
    "\n",
    "    plt.xticks(x_axis, labels)\n",
    "    plt.xlabel(xTitle)\n",
    "    plt.ylabel(yTitle)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "xLabels = ['DEL','DUP','INV']\n",
    "uniqueLabels = ['1','2','3','4','5','6','7','8','9','10',\n",
    "                '11','12','13','14','15','16','17','18','19','20','21','22','X','Y']\n",
    "\n",
    "deldf = mergedSVdf.loc[(mergedSVdf['kics'] == 'DEL') | (mergedSVdf['lfs']=='DEL')]\n",
    "dupdf = mergedSVdf.loc[(mergedSVdf['kics'] == 'DUP') | (mergedSVdf['lfs']=='DUP')]\n",
    "invdf = mergedSVdf.loc[(mergedSVdf['kics'] == 'INV') | (mergedSVdf['lfs']=='INV')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602a3ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overall\n",
    "BarGraphNormalized('kics', 'lfs', mergedSVdf, 'kics', 'lfs', 'Groups', 'Frequency/NumSamples', \n",
    "                   kicsSVnum, lfsSVnum, xLabels)\n",
    "\n",
    "#Deletions \n",
    "BarGraphNormalized('kics', 'lfs', deldf, 'kChrom', 'lChrom', 'Chromosomes', 'Frequency/num', \n",
    "                   kicsSVnum, lfsSVnum, uniqueLabels)\n",
    "\n",
    "#Duplicates\n",
    "BarGraphNormalized('kics', 'lfs', dupdf, 'kChrom', 'lChrom', 'Chromosomes', 'Frequency/num', \n",
    "                   kicsSVnum, lfsSVnum, uniqueLabels)\n",
    "\n",
    "#Inversions\n",
    "BarGraphNormalized('kics', 'lfs', invdf, 'kChrom', 'lChrom', 'Chromosomes', 'Frequency', \n",
    "                   kicsSVnum, lfsSVnum, uniqueLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42117c2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "location is put on hold for now since intron3 - intron5 does not mean it only impacts introns, may also impact exons\n",
    "'''\n",
    "\n",
    "# #LOCATION \n",
    "# mergedLocdf = pd.DataFrame(data={'kics':kicsSVR['location'], 'lfs':lfsSVR['location'], \n",
    "#                                  'kId':kicsSVR['sample_id'], 'lId':lfsSVR['sample_id']})\n",
    "\n",
    "# kicsLocdf = pd.DataFrame(data={'loc':kicsSVR['location'], 'id':kicsSVR['sample_id']})\n",
    "# lfsLocdf = pd.DataFrame(data={'loc':lfsSVR['location'], 'id':lfsSVR['sample_id']})\n",
    "\n",
    "# kicsLocdf[['start','end']] = kicsLocdf['loc'].str.split('-', expand=True)\n",
    "# lfsLocdf[['start','end']] = lfsLocdf['loc'].str.split('-', expand=True)\n",
    "\n",
    "\n",
    "# def locationType(row):\n",
    "#     if ('tx' in row['start'] or 'tx' in row['end']): \n",
    "#         return 'All'\n",
    "        \n",
    "#     elif('intron' in row['start'] and 'intron' in row['end']):\n",
    "#          return 'intron'\n",
    "\n",
    "#     elif('exon' in row['start'] and 'exon' in row['end']):\n",
    "#          return 'exon'\n",
    "            \n",
    "#     else:\n",
    "#         return 'intron and exon'\n",
    "\n",
    "# #print(kicsLocdf)\n",
    "# kicsLocdf['locType'] = kicsLocdf.apply(lambda row: locationType(row), axis=1)\n",
    "# lfsLocdf['locType'] = lfsLocdf.apply(lambda row: locationType(row), axis=1)\n",
    "\n",
    "# kicsTry = kicsLocdf.groupby(['id','locType']).size().unstack(fill_value=0)\n",
    "# lfsTry = lfsLocdf.groupby(['id','locType']).size().unstack(fill_value=0)\n",
    "\n",
    "# kicsTry['dataset'] = 'kics'\n",
    "\n",
    "# lfsTry['dataset'] = 'lfs'\n",
    "\n",
    "# tryMerge = pd.concat([kicsTry, lfsTry])\n",
    "# print(kicsTry)\n",
    "\n",
    "# sns.boxplot(data=tryMerge, x=)\n",
    "# # newMergedDf.rename(columns = {0:'occ'}, inplace = True)\n",
    "# # newMergedDf.reset_index(inplace=True)\n",
    "# # newMergedDf.rename(columns = {'index':'chrom'}, inplace = True)\n",
    "\n",
    "# sns.boxplot(data=tryMerge, x='location', y='occ', hue='dataset', palette='spring')\n",
    "\n",
    "# #plt.show()\n",
    "        \n",
    "# # for i in kicsLocdf['kics']: \n",
    "# #     start,end = i.split(\"-\") \n",
    "# #     tempList.append((start,end)) \n",
    "# #     if (start.contains('tx') or end.contains('tx')): \n",
    "# #         tempList2.append('All')\n",
    "# #     elif(start.contains('intron') and end.contains('intron')):\n",
    "# #          tempList2.append('intron')\n",
    "\n",
    "# #     elif(start.contains('exon') and end.contains('exon')):\n",
    "# #          tempList2.append('exon')\n",
    "\n",
    "# #     else:\n",
    "# #         tempList2.append(\"intron and exon\")\n",
    "# # print(kicsLocdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb024b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "global mergedGDAF \n",
    "mergedGDAF = pd.DataFrame(data = {'kics':kicsSVF['GD_AF'],\n",
    "                                'lfs':lfsSVF['GD_AF']})\n",
    "\n",
    "mergedGDAF.replace(to_replace = [-1], value = np.nan, inplace=True)\n",
    "mergedGDAF.replace(to_replace = ['-1'], value = np.nan, inplace=True)\n",
    "\n",
    "\n",
    "def maxGDAFFilter(colName: str, df: pd.DataFrame):\n",
    "    temp = df[colName].str.contains(pat=',')\n",
    "    Index = list(np.where(temp == True)[0])\n",
    "    temp = df[colName].iloc[Index]\n",
    "    tempIndex = temp.index\n",
    "\n",
    "    for i in tempIndex:\n",
    "        tempList = temp[i].split(',')\n",
    "        tempList = [float(a) for a in tempList]\n",
    "        maxTemp = max(tempList)\n",
    "        df[colName][i] = maxTemp\n",
    "\n",
    "    df[colName] = df[colName].astype('float64')\n",
    "    \n",
    "maxGDAFFilter('kics', mergedGDAF)\n",
    "maxGDAFFilter('lfs', mergedGDAF)\n",
    "mergedGDAF.loc[mergedGDAF['kics'] < 0, 'kics'] = np.nan\n",
    "mergedGDAF.loc[mergedGDAF['lfs'] < 0, 'lfs'] = np.nan\n",
    "\n",
    "import seaborn as sns\n",
    "def BoxGraphMulti(df: pd.DataFrame, xCol, yCol, compCol):\n",
    "    sns.boxplot(data=df, x=xCol, y=yCol, hue=compCol, palette='spring')\n",
    "    #plt.show()\n",
    "\n",
    "def boxplotPoints(title:list, column:list, df: pd.DataFrame , sizeH=20.50, sizeV=17.50, col='red', trans=0.25):\n",
    "    plt.rcParams[\"figure.figsize\"] = [sizeH, sizeV]\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "    data = pd.DataFrame({\n",
    "        t: df[c] for t,c in zip(title, column)})\n",
    "    \n",
    "    #print(data)\n",
    "    plotTest = data\n",
    "    plotTest = plotTest.stack().to_frame().reset_index().rename(columns={'level_1': 'iden', 0: 'value'}).drop('level_0', axis='columns')\n",
    "    plotTest['cat'] = 1\n",
    "    #print(plotTest.head(50))\n",
    "    #data.boxplot()\n",
    "    #BoxGraphMulti(plotTest, 'cat', 'value', 'iden')\n",
    "    sns.boxplot(data=plotTest, x='iden', y='value')\n",
    "    \n",
    "    #plot with boxplot\n",
    "    sns.stripplot(x = 'iden',\n",
    "              y = 'value',\n",
    "                  color = 'red',\n",
    "                  alpha = 0.25,\n",
    "              data = plotTest)\n",
    "    \n",
    "#     for i, d in enumerate(data):\n",
    "#         print(i)\n",
    "#         y = data[d]\n",
    "#         x = np.random.normal(i, 0.04, len(y))\n",
    "#         plt.scatter(x, y, color = col, alpha = trans)\n",
    "    \n",
    "    list1 = df[column[0]].dropna()\n",
    "    list2 = df[column[1]].dropna()\n",
    "    print(mannwhitneyu(list1,list2))\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "titles = ['kics','lfs']\n",
    "columns = titles\n",
    "\n",
    "boxplotPoints(titles, columns, mergedGDAF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ba62e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Testing group by\n",
    "\n",
    "\"\"\"\n",
    "#probably a better way to do this\n",
    "\n",
    "kicsSVTypedf = pd.DataFrame(data = {'kics':kicsSVF['SV type'], \n",
    "                                  'kId':kicsSVF['sample_id']})\n",
    "lfsSVTypedf = pd.DataFrame(data = {'lId':lfsSVF['sample_id'],\n",
    "                                  'lfs':lfsSVF['SV type']})\n",
    "\n",
    "#temp = mergedSVdf.groupby(['kId']).value_counts() #not sure how to use this, unsure if it's missing anything\n",
    "\n",
    "##kics\n",
    "ktemp = kicsSVTypedf.groupby(['kId']).value_counts()\n",
    "\n",
    "##lfs\n",
    "ltemp = lfsSVTypedf.groupby(['lId']).value_counts()\n",
    "\n",
    "#print(ktemp.head(30))\n",
    "#print(ktemp.index.get_level_values(0))\n",
    "\n",
    "#get unique identifiers\n",
    "\n",
    "uniqueK = kicsSVTypedf['kId'].unique()\n",
    "uniqueL = lfsSVTypedf['lId'].unique()\n",
    "\n",
    "#probably a better way, but itterate through the series and get the data \n",
    "\n",
    "def makeDataSet(identifiers, series: pd.Series, secondIndex: str)->list:\n",
    "    \n",
    "    dataList = []\n",
    "    \n",
    "    for i in identifiers:\n",
    "        try:\n",
    "            dataList.append(series[(i, secondIndex)])\n",
    "        except:\n",
    "            #pass\n",
    "            dataList.append(0)\n",
    "\n",
    "    return(dataList)\n",
    "\n",
    "\n",
    "        \n",
    "def makeUnequalDF(list1: list, list2: list) -> pd.DataFrame: #only for kics vs lfs D:\n",
    "    tempDict = dict(kics = list1, lfs = list2)\n",
    "    df = pd.DataFrame(dict([(k, pd.Series(v)) for k,v in tempDict.items()]))\n",
    "    return df\n",
    "\n",
    "\n",
    "kDelData = makeDataSet(uniqueK, ktemp, 'DEL')\n",
    "lDelData = makeDataSet(uniqueL, ltemp, 'DEL')\n",
    "tempDelDF = makeUnequalDF(kDelData, lDelData)\n",
    "\n",
    "boxplotPoints(titles, columns, tempDelDF, 10, 7)\n",
    "\n",
    "kDupData = makeDataSet(uniqueK, ktemp, 'DUP')\n",
    "lDupData = makeDataSet(uniqueL, ltemp, 'DUP')\n",
    "tempDupDF = makeUnequalDF(kDupData, lDupData)\n",
    "\n",
    "boxplotPoints(titles, columns, tempDupDF, 10, 7)\n",
    "\n",
    "kInvData = makeDataSet(uniqueK, ktemp, 'INV')\n",
    "lInvData = makeDataSet(uniqueL, ltemp, 'INV')\n",
    "tempInvDF = makeUnequalDF(kInvData, lInvData)\n",
    "\n",
    "boxplotPoints(titles, columns, tempInvDF, 10, 7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28142a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Chromosome Specific\n",
    "Cleaned up\n",
    "\n",
    "\"\"\"\n",
    "import seaborn as sns\n",
    "\n",
    "def formatDataFrame(df: pd.DataFrame, groupByList: list, normalizeList: list, \n",
    "                    iterateList: list, labels: list, typeSV: str ) -> tuple:\n",
    "    \n",
    "    #kicsMore, lfsMore, ['id','SV','chrom'], nomBPChrom, \n",
    "\n",
    "    dfGrouped = df.groupby(groupByList).size().unstack(fill_value=0)\n",
    "    #print(dfGrouped)\n",
    "    dfReg = pd.DataFrame()\n",
    "    dfNorm = pd.DataFrame()\n",
    "    df1WC = pd.DataFrame()\n",
    "    df2WC = pd.DataFrame()\n",
    "    \n",
    "    for i in iterateList:\n",
    "        tempList = []\n",
    "        \n",
    "        try:\n",
    "            series = dfGrouped.loc[(i,typeSV)]\n",
    "            #print(series)\n",
    "            \n",
    "        except:\n",
    "            series = pd.Series(0, index=labels)\n",
    "            \n",
    "        for j,div in zip(labels, normalizeList):\n",
    "            tempList.append(series[j]/div)\n",
    "            \n",
    "        d = {'chrom':labels, 'normalized':tempList}\n",
    "        tempdf = pd.DataFrame(d)\n",
    "\n",
    "        dfNorm = pd.concat([dfNorm, tempdf], axis=0)\n",
    "        dfReg = pd.concat([dfReg, series], axis=0) \n",
    "    \n",
    "    return(dfReg, dfNorm)\n",
    "\n",
    "# def BoxGraphMulti(df: pd.DataFrame, xCol, yCol, compCol):\n",
    "#     sns.boxplot(data=df, x=xCol, y=yCol, hue=compCol, palette='spring')\n",
    "#     plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "kicsMore = pd.DataFrame(data = {'SV':kicsSVF['SV type'], 'chrom':kicsSVF['SV chrom'], \n",
    "                                  'id':kicsSVF['sample_id']})\n",
    "lfsMore = pd.DataFrame(data = {'id':lfsSVF['sample_id'], 'chrom':lfsSVF['SV chrom'],\n",
    "                                  'SV':lfsSVF['SV type']})\n",
    "\n",
    "numBPChrom = [249250621, 243199373, 198022430, 191154276, 180915260, \n",
    "              171115067, 159138663, 146364022, 141213431, 135534747,\n",
    "              135006516, 133851895, 115169878, 107349540, 102531392,\n",
    "              90354753, 81195210, 78077248, 59128983, 63025520,\n",
    "              48129895, 51304566, 155270560, 59373566]\n",
    "\n",
    "grouping = ['id', 'SV', 'chrom']\n",
    "\n",
    "\n",
    "'''\n",
    "If you have time, you should make it so that the plot can have the points showing/scattered plot\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7149ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Normalised and Regular Graph\n",
    "\"\"\"\n",
    "\n",
    "#rename things later and put into function/integrate but this is the statistical test T-T\n",
    "dog = kicsMore.groupby(grouping).size().unstack(fill_value=0)\n",
    "dog = dog.stack().unstack(1)\n",
    "#print(type(dog))\n",
    "dog = dog.drop(['DUP','INV'], axis=1)\n",
    "dog = dog.stack().unstack(1)\n",
    "\n",
    "cat = lfsMore.groupby(grouping).size().unstack(fill_value=0)\n",
    "cat = cat.stack().unstack(1)\n",
    "#print(type(dog))\n",
    "cat = cat.drop(['DUP','INV'], axis=1)\n",
    "cat = cat.stack().unstack(1)\n",
    "\n",
    "for i in uniqueLabels:\n",
    "    print(i)\n",
    "    print(mannwhitneyu(dog[i].values, cat[i].values))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "newKdf, normKdf = formatDataFrame(kicsMore, grouping, numBPChrom, uniqueK, uniqueLabels, 'DEL')\n",
    "newLdf, normLdf = formatDataFrame(lfsMore, grouping, numBPChrom, uniqueL, uniqueLabels, 'DEL')\n",
    "\n",
    "#print(newKdf.index)\n",
    "#print(newKdf.pivot( columns='index', values=0))\n",
    "\n",
    "newKdf['dataset'] = 'kics'\n",
    "newLdf['dataset'] = 'lfs'\n",
    "normKdf['dataset'] = 'kics'\n",
    "normLdf['dataset'] = 'lfs'\n",
    "\n",
    "newMergedDf = pd.concat([newKdf, newLdf])\n",
    "newMergedDf.rename(columns = {0:'occ'}, inplace = True)\n",
    "newMergedDf.reset_index(inplace=True)\n",
    "newMergedDf.rename(columns = {'index':'chrom'}, inplace = True)\n",
    "\n",
    "BoxGraphMulti(newMergedDf, 'chrom', 'occ', 'dataset')\n",
    "\n",
    "normMergedDf = pd.concat([normKdf, normLdf])\n",
    "normMergedDf.reset_index(inplace=True)\n",
    "\n",
    "BoxGraphMulti(normMergedDf, 'chrom', 'normalized', 'dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc16b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Dup\n",
    "\n",
    "\"\"\"\n",
    "newKdf, normKdf = formatDataFrame(kicsMore, grouping, numBPChrom, uniqueK, uniqueLabels, 'DUP')\n",
    "newLdf, normLdf = formatDataFrame(lfsMore, grouping, numBPChrom, uniqueL, uniqueLabels, 'DUP')\n",
    "\n",
    "newKdf['dataset'] = 'kics'\n",
    "newLdf['dataset'] = 'lfs'\n",
    "normKdf['dataset'] = 'kics'\n",
    "normLdf['dataset'] = 'lfs'\n",
    "\n",
    "newMergedDf = pd.concat([newKdf, newLdf])\n",
    "newMergedDf.rename(columns = {0:'occ'}, inplace = True)\n",
    "newMergedDf.reset_index(inplace=True)\n",
    "newMergedDf.rename(columns = {'index':'chrom'}, inplace = True)\n",
    "\n",
    "BoxGraphMulti(newMergedDf, 'chrom', 'occ', 'dataset')\n",
    "\n",
    "normMergedDf = pd.concat([normKdf, normLdf])\n",
    "normMergedDf.reset_index(inplace=True)\n",
    "\n",
    "BoxGraphMulti(normMergedDf, 'chrom', 'normalized', 'dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c67ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "INV\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "newKdf, normKdf = formatDataFrame(kicsMore, grouping, numBPChrom, uniqueK, uniqueLabels, 'INV')\n",
    "newLdf, normLdf = formatDataFrame(lfsMore, grouping, numBPChrom, uniqueL, uniqueLabels, 'INV')\n",
    "\n",
    "newKdf['dataset'] = 'kics'\n",
    "newLdf['dataset'] = 'lfs'\n",
    "normKdf['dataset'] = 'kics'\n",
    "normLdf['dataset'] = 'lfs'\n",
    "\n",
    "newMergedDf = pd.concat([newKdf, newLdf])\n",
    "newMergedDf.rename(columns = {0:'occ'}, inplace = True)\n",
    "newMergedDf.reset_index(inplace=True)\n",
    "newMergedDf.rename(columns = {'index':'chrom'}, inplace = True)\n",
    "\n",
    "BoxGraphMulti(newMergedDf, 'chrom', 'occ', 'dataset')\n",
    "\n",
    "normMergedDf = pd.concat([normKdf, normLdf])\n",
    "normMergedDf.reset_index(inplace=True)\n",
    "\n",
    "BoxGraphMulti(normMergedDf, 'chrom', 'normalized', 'dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d0054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" filter the df for CDS_length \"\"\"\n",
    "\n",
    "kicsSVR = kicsSVdf.loc[kicsSVdf['AnnotSV type'] == 'split'] \n",
    "lfsSVR = lfsSVdf.loc[lfsSVdf['AnnotSV type'] == 'split']\n",
    "mergedCDSdf = pd.DataFrame(data = {'kics':kicsSVR['CDS length'], 'lfs':lfsSVR['CDS length']})\n",
    "boxplotPoints(titles, columns, mergedCDSdf, sizeV = 10)\n",
    "#print(mergedCDSdf.head(50)) #they look the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ad816b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
